# Roman Urdu Toxicity Detection — Demo
**Author:** Waffa Shahzad

## Project Summary
I built a fine-tuned multilingual BERT (mBERT) model to detect toxic and offensive content in Roman Urdu and code-mixed Urdu-English comments. This demo includes dataset creation, model training, and prediction examples.

## How It Works
- Labeled dataset for Roman Urdu/code-mixed comments
- Fine-tuned mBERT classifier with multiple labels
- Predictions demo with example inputs and outputs
- Screenshots of training and predictions included

## Skills & Tools
- Python, Google Colab, HuggingFace Transformers
- NLP, Text Classification, Dataset creation, Model fine-tuning

## Screenshots
- `trainer_output.png` — Model training output  
- `predictions_output.png` — Example predictions  

## Colab Notebook
[Open Demo in Google Colab](https://colab.research.google.com/drive/1cTX4aisZCnFqZAb7mwCAraP2OSdYhLRY?usp=sharing)

## Contact
Email: waffashahzad333@example.com  
LinkedIn: https://www.linkedin.com/in/waffa-shahzad-17aaa9286


