# Roman Urdu Toxicity Detection â€” Demo
**Author:** Waffa Shahzad

## Project summary
I fine-tuned a multilingual BERT (mBERT) model to detect toxic and offensive content in Roman Urdu and code-mixed Urdu-English comments. This demo shows dataset creation, model training, and prediction examples.

## What I built
- Labeled dataset (starter sample) for Roman Urdu / code-mixed comments  
- Fine-tuned mBERT classifier with 4 classes: Safe, Mild Toxic, Offensive, Abusive  
- Simple inference demo (Colab notebook + screenshots)

## How to run (quick)
1. Open the Colab notebook `roman_urdu_demo.ipynb`.  
2. Run cells to load dataset, train model and try demo inputs.  
3. See predictions and screenshots in this repo.

## Results (example)
- Training output and loss: see `trainer_output.png`  
- Example predictions: see `predictions_output.png`

## Skills & Tools
- Python, Pandas, HuggingFace Transformers, Google Colab  
- Text classification, tokenization, model fine-tuning

## Contact
**Email:** waffashahzad333@gmail.com  
**LinkedIn:** https://www.linkedin.com/in/waffa-shahzad-17aaa9286/


